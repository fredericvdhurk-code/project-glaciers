{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26404947-b9ce-41ea-af6a-8565075e8c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def process_glaciers_list(initial_list_df):\n",
    "    \"\"\"\n",
    "    Process the raw glaciers list to get a clean DataFrame.\n",
    "    \"\"\"\n",
    "    # Drop the first 3 rows\n",
    "    glaciers_list_df = initial_list_df.drop(index=[0, 1]).reset_index(drop=True)\n",
    "\n",
    "    # Rename the first column to 'SWISS GLACIER LIST (AVAILABLE DATA)' if it isn't already named\n",
    "    glaciers_list_df.columns = ['SWISS GLACIER LIST (AVAILABLE DATA)']\n",
    "\n",
    "    # Split data into several columns\n",
    "    glaciers_list_df = glaciers_list_df[\n",
    "        'SWISS GLACIER LIST (AVAILABLE DATA)'\n",
    "    ].str.split(',', expand=True)\n",
    "\n",
    "    # Set first row as column headers\n",
    "    #new_headers_list = glaciers_list_df.iloc[0]\n",
    "    #glaciers_list_df = glaciers_list_df[1:]\n",
    "    #glaciers_list_df.columns = new_headers_list\n",
    "\n",
    "    # Rename columns to include measurement units\n",
    "    glaciers_list_df.rename(\n",
    "        columns={\n",
    "            glaciers_list_df.columns[0]: 'glacier name',\n",
    "            glaciers_list_df.columns[1]: 'glacier ID',\n",
    "            glaciers_list_df.columns[2]: 'coordx (X_LV95)',\n",
    "            glaciers_list_df.columns[3]: 'coordy (Y_LV95)',\n",
    "            glaciers_list_df.columns[4]: 'glacier area (km2)',\n",
    "            glaciers_list_df.columns[5]: 'survey year for glacier area (yyyy)',\n",
    "            glaciers_list_df.columns[6]: 'length change',\n",
    "            glaciers_list_df.columns[7]: 'mass balance',\n",
    "            glaciers_list_df.columns[8]: 'volume change'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    return glaciers_list_df\n",
    "\n",
    "def process_length_change(initial_length_df):\n",
    "    \"\"\"\n",
    "    Process the raw length change DataFrame.\n",
    "    \"\"\"\n",
    "    # Delete rows 1 & 2\n",
    "    length_change_df = initial_length_df.drop(index=[0, 1])\n",
    "\n",
    "\n",
    "    # Rename the first column to 'SWISS GLACIER LENGTH CHANGE'\n",
    "    length_change_df.columns = ['SWISS GLACIER LENGTH CHANGE']\n",
    "    \n",
    "    # Split data into several columns\n",
    "    length_change_df = length_change_df[\n",
    "        'SWISS GLACIER LENGTH CHANGE'\n",
    "    ].str.split(',', expand=True)\n",
    "\n",
    "    # Reset index and set first row as column headers\n",
    "    length_change_df = length_change_df.reset_index(drop=True)\n",
    "    #new_headers_length = length_change_df.iloc[0]\n",
    "    #length_change_df = length_change_df[1:]\n",
    "    #length_change_df.columns = new_headers_length\n",
    "\n",
    "    # Rename columns to include measurement units\n",
    "    length_change_df.rename(\n",
    "        columns={\n",
    "            length_change_df.columns[0]: 'glacier name',\n",
    "            length_change_df.columns[1]: 'glacier ID',\n",
    "            length_change_df.columns[2]: 'start date of observation (yyyy-mm-dd)',\n",
    "            length_change_df.columns[3]: 'quality of start date',\n",
    "            length_change_df.columns[4]: 'end date of observation (yyyy-mm-dd)',\n",
    "            length_change_df.columns[5]: 'quality of end date',\n",
    "            length_change_df.columns[6]: 'length change',\n",
    "            length_change_df.columns[7]: 'elevation of glacier tongue',\n",
    "            length_change_df.columns[8]: 'observer'\n",
    "            },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    return length_change_df\n",
    "\n",
    "\n",
    "def process_mass_balance_hy(initial_mass_balance_hy_df):\n",
    "    \"\"\"\n",
    "    Process the raw mass balance (hydrological year) DataFrame.\n",
    "    \"\"\"\n",
    "    # Drop unnecessary rows\n",
    "    mass_balance_hy_df = initial_mass_balance_hy_df.drop(index=[0, 1])\n",
    "    \n",
    "    # Rename the first column to 'SWISS GLACIER MASS BALANCE (HYDROLOGICAL YEAR)'\n",
    "    mass_balance_hy_df.columns = ['SWISS GLACIER MASS BALANCE (HYDROLOGICAL YEAR)']\n",
    "\n",
    "    # Split data into several columns\n",
    "    mass_balance_hy_df = mass_balance_hy_df[\n",
    "        'SWISS GLACIER MASS BALANCE (HYDROLOGICAL YEAR)'\n",
    "    ].str.split(',', expand=True)\n",
    "\n",
    "    # Reset index\n",
    "    mass_balance_hy_df = mass_balance_hy_df.reset_index(drop=True)\n",
    "\n",
    "    # Merge columns 13-16 into a single column\n",
    "#    mass_balance_hy_df['merged columns 13,14,15,16'] = (\n",
    "#        mass_balance_hy_df[mass_balance_hy_df.columns[13]].astype(str) + ' ' +\n",
    "#        mass_balance_hy_df[mass_balance_hy_df.columns[14]].astype(str) + ' ' +\n",
    "#        mass_balance_hy_df[mass_balance_hy_df.columns[15]].astype(str) + ' ' +\n",
    "#        mass_balance_hy_df[mass_balance_hy_df.columns[16]].astype(str)\n",
    "#    )\n",
    "\n",
    "    # Drop the original columns 13-16\n",
    "    mass_balance_hy_df = mass_balance_hy_df.drop(\n",
    "        columns=[\n",
    "            mass_balance_hy_df.columns[13],\n",
    "            mass_balance_hy_df.columns[14],\n",
    "            mass_balance_hy_df.columns[15],\n",
    "            mass_balance_hy_df.columns[16]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Set first row as column headers\n",
    "#    new_headers_mb_hy = mass_balance_hy_df.iloc[0]\n",
    "#    mass_balance_hy_df = mass_balance_hy_df[1:]\n",
    "#    mass_balance_hy_df.columns = new_headers_mb_hy\n",
    "\n",
    "    # Rename 'observer' column and clean it\n",
    "#    mass_balance_hy_df = mass_balance_hy_df.rename(columns={'observer None None None': 'observer'})\n",
    "#    mass_balance_hy_df['observer'] = (\n",
    "#        mass_balance_hy_df['observer']\n",
    "#        .str.replace('None', '', regex=False)\n",
    "#        .str.replace(' - ', ' -', regex=False)\n",
    "#        .str.strip()\n",
    "#    )\n",
    "\n",
    "    # Rename columns to include units\n",
    "    mass_balance_hy_df.rename(\n",
    "        columns={\n",
    "            mass_balance_hy_df.columns[0]: 'glacier name',\n",
    "            mass_balance_hy_df.columns[1]: 'glacier ID',\n",
    "            mass_balance_hy_df.columns[2]: 'start date of observation (yyyy-mm-dd)',\n",
    "            mass_balance_hy_df.columns[3]: 'end date of winter observation (yyyy-mm-dd)',\n",
    "            mass_balance_hy_df.columns[4]: 'end date of observation (yyyy-mm-dd)',\n",
    "            mass_balance_hy_df.columns[5]: 'winter mass balance (mm w.e.)',\n",
    "            mass_balance_hy_df.columns[6]: 'summer mass balance (mm w.e.)',\n",
    "            mass_balance_hy_df.columns[7]: 'annual mass balance (mm w.e.)',\n",
    "            mass_balance_hy_df.columns[8]: 'equilibrium line altitude (m asl.)',\n",
    "            mass_balance_hy_df.columns[9]: 'accumulation area ratio (%)',\n",
    "            mass_balance_hy_df.columns[10]: 'glacier area (km2)',\n",
    "            mass_balance_hy_df.columns[11]: 'minimum elevation of glacier (m asl.)',\n",
    "            mass_balance_hy_df.columns[12]: 'maximum elevation of glacier (m asl.)'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    return mass_balance_hy_df\n",
    "\n",
    "def process_mass_balance_hy_eb(initial_mass_balance_hy_eb_df):\n",
    "    \"\"\"\n",
    "    Process the raw mass balance (hydrological year with elevation bins) DataFrame.\n",
    "    \"\"\"\n",
    "    # Drop unnecessary rows\n",
    "    mass_balance_hy_eb_df = initial_mass_balance_hy_eb_df.drop(index=[0, 1])\n",
    "\n",
    "    # Rename the first column to 'SWISS GLACIER MASS BALANCE (HYDROLOGICAL YEAR) ELEVATION BINS'\n",
    "    mass_balance_hy_eb_df.columns = ['SWISS GLACIER MASS BALANCE (HYDROLOGICAL YEAR) ELEVATION BINS']\n",
    "\n",
    "    # Split data into several columns\n",
    "    mass_balance_hy_eb_df = mass_balance_hy_eb_df[\n",
    "        'SWISS GLACIER MASS BALANCE (HYDROLOGICAL YEAR) ELEVATION BINS'\n",
    "    ].str.split(',', expand=True)\n",
    "\n",
    "    # Reset index\n",
    "    mass_balance_hy_eb_df = mass_balance_hy_eb_df.reset_index(drop=True)\n",
    "\n",
    "    # Merge columns 11-14 into a single column\n",
    "#    mass_balance_hy_eb_df['merged columns 11,12,13,14'] = (\n",
    "#        mass_balance_hy_eb_df[mass_balance_hy_eb_df.columns[11]].astype(str) + ' ' +\n",
    "#        mass_balance_hy_eb_df[mass_balance_hy_eb_df.columns[12]].astype(str) + ' ' +\n",
    "#        mass_balance_hy_eb_df[mass_balance_hy_eb_df.columns[13]].astype(str) + ' ' +\n",
    "#        mass_balance_hy_eb_df[mass_balance_hy_eb_df.columns[14]].astype(str)\n",
    "#    )\n",
    "\n",
    "    # Drop the original columns 11-14\n",
    "    mass_balance_hy_eb_df = mass_balance_hy_eb_df.drop(\n",
    "        columns=[\n",
    "            mass_balance_hy_eb_df.columns[11],\n",
    "            mass_balance_hy_eb_df.columns[12],\n",
    "            mass_balance_hy_eb_df.columns[13],\n",
    "            mass_balance_hy_eb_df.columns[14]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Set first row as column headers\n",
    "#    new_headers_mb_hy_eb = mass_balance_hy_eb_df.iloc[0]\n",
    "#    mass_balance_hy_eb_df = mass_balance_hy_eb_df[1:]\n",
    "#    mass_balance_hy_eb_df.columns = new_headers_mb_hy_eb\n",
    "\n",
    "    # Rename 'observer' column and clean it\n",
    "#    mass_balance_hy_eb_df = mass_balance_hy_eb_df.rename(columns={'observer None None None': 'observer'})\n",
    "#    mass_balance_hy_eb_df['observer'] = (\n",
    "#        mass_balance_hy_eb_df['observer']\n",
    "#        .str.replace('None', '', regex=False)\n",
    "#        .str.replace(' - ', ' -', regex=False)\n",
    "#        .str.strip()\n",
    "#    )\n",
    "\n",
    "    # Rename columns to include units\n",
    "    mass_balance_hy_eb_df.rename(\n",
    "        columns={\n",
    "            mass_balance_hy_eb_df.columns[0]: 'glacier name',\n",
    "            mass_balance_hy_eb_df.columns[1]: 'glacier ID',\n",
    "            mass_balance_hy_eb_df.columns[2]: 'start date of observation (yyyy-mm-dd)',\n",
    "            mass_balance_hy_eb_df.columns[3]: 'end date of winter observation (yyyy-mm-dd)',\n",
    "            mass_balance_hy_eb_df.columns[4]: 'end date of observation (yyyy-mm-dd)',\n",
    "            mass_balance_hy_eb_df.columns[5]: 'winter mass balance (mm w.e.)',\n",
    "            mass_balance_hy_eb_df.columns[6]: 'summer mass balance (mm w.e.)',\n",
    "            mass_balance_hy_eb_df.columns[7]: 'annual mass balance (mm w.e.)',\n",
    "            mass_balance_hy_eb_df.columns[8]: 'area of elevation bin (km2)',\n",
    "            mass_balance_hy_eb_df.columns[9]: 'lower elevation of bin (m asl.)',\n",
    "            mass_balance_hy_eb_df.columns[10]: 'upper elevation of bin (m asl.)'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    return mass_balance_hy_eb_df\n",
    "\n",
    "\n",
    "def clean_weather_metadata(metadata_raw):\n",
    "    \"\"\"\n",
    "    Clean weather metadata by selecting relevant columns.\n",
    "    \"\"\"\n",
    "    if metadata_raw is not None:\n",
    "        metadata = metadata_raw[['parameter_shortname', 'parameter_description_en', 'parameter_unit']]\n",
    "        return metadata\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def process_city_weather(city_weather_raw):\n",
    "    \"\"\"\n",
    "    Process weather data for a city DataFrame:\n",
    "    - Convert 'reference_timestamp' to datetime and set as index.\n",
    "    - Filter data between 1914-10-01 and 2025-10-01.\n",
    "    - Drop NA columns and 'reference_timestamp'.\n",
    "    - Add 'year-month' column and reorder columns.\n",
    "    - Select and rename 'rhs150m0' and 'ths200m0' columns.\n",
    "    \"\"\"\n",
    "    # Convert 'reference_timestamp' to datetime and set as index\n",
    "    city_weather_raw['date'] = pd.to_datetime(city_weather_raw['reference_timestamp'], format='%d.%m.%Y %H:%M')\n",
    "    city_weather = city_weather_raw.drop(columns=['station_abbr'])\n",
    "    city_weather = city_weather.set_index('date')\n",
    "\n",
    "    # Filter data between 1914-10-01 and 2025-10-01\n",
    "    city_1914 = city_weather[\n",
    "        (city_weather.index >= '1914-10-01') &\n",
    "        (city_weather.index < '2025-10-01')\n",
    "    ]\n",
    "    city_1914 = city_1914.dropna(axis=1)\n",
    "    city_1914 = city_1914.drop('reference_timestamp', axis=1, errors='ignore')\n",
    "\n",
    "    # Add 'year-month' column and reorder\n",
    "    city_1914['year-month'] = city_1914.index.to_series().dt.to_period('M').astype(str)\n",
    "    cols = city_1914.columns.tolist()\n",
    "    cols.insert(0, cols.pop(cols.index('year-month')))\n",
    "    city_1914 = city_1914[cols]\n",
    "\n",
    "    # Select and rename columns\n",
    "    city_processed = city_1914[['year-month', 'rhs150m0', 'ths200m0']].copy()\n",
    "    city_processed.rename(\n",
    "        columns={\n",
    "            'rhs150m0': 'total precipitation (mm)',\n",
    "            'ths200m0': 'mean temperature (°C)'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    return city_processed\n",
    "\n",
    "def calculate_hydrological_year_aggregates(city_data):\n",
    "    \"\"\"\n",
    "    Calculate hydrological year aggregates for precipitation and temperature from city weather data.\n",
    "    - Groups data into hydrological years (October to September).\n",
    "    - Calculates total precipitation and mean temperature for each hydrological year.\n",
    "    \"\"\"\n",
    "    # Calculate total precipitation for hydrological years\n",
    "    city_p = city_data[['total precipitation (mm)']].copy()\n",
    "    hy_data_p = city_p.groupby(np.arange(len(city_p)) // 12).sum()\n",
    "\n",
    "    # Generate the date range for hydrological years (October to September)\n",
    "    start_date = '1914-10-01'\n",
    "    end_date = '2024-10-01'\n",
    "    hy_dates = pd.date_range(start=start_date, end=end_date, freq='YS-OCT')\n",
    "    hy_data_p.index = hy_dates\n",
    "\n",
    "    # Calculate mean temperature for hydrological years\n",
    "    city_temp = city_data[['mean temperature (°C)']].copy()\n",
    "    city_temp[\"days_in_month\"] = city_temp.index.days_in_month\n",
    "    city_temp['temp_times_days'] = city_temp['mean temperature (°C)'] * city_temp['days_in_month']\n",
    "\n",
    "    n = 12  # Number of rows per group (12 months)\n",
    "    hy_mean_temp = pd.DataFrame({\n",
    "        'hy mean temperature (°C)': [\n",
    "            city_temp['temp_times_days'].iloc[i:i + n].sum() /\n",
    "            city_temp['days_in_month'].iloc[i:i + n].sum()\n",
    "            for i in range(0, len(city_temp), n)\n",
    "        ]\n",
    "    })\n",
    "    hy_mean_temp = hy_mean_temp.round(1)\n",
    "    hy_mean_temp.index = hy_dates\n",
    "\n",
    "    # Combine precipitation and temperature data\n",
    "    hy_data = pd.concat([hy_data_p, hy_mean_temp], axis=1)\n",
    "    hy_data = hy_data.round(1)\n",
    "    hy_data[\"date\"] = hy_data.index\n",
    "    hy_data.rename(columns={'total precipitation (mm)': 'hy total precipitation (mm)'}, inplace=True)\n",
    "\n",
    "    return hy_data\n",
    "\n",
    "def calculate_seasonal_aggregates(city_data):\n",
    "    \"\"\"\n",
    "    Calculate seasonal aggregates for precipitation and temperature from city weather data.\n",
    "    Returns two DataFrames: winter and summer seasonal aggregates.\n",
    "    \"\"\"\n",
    "    # Define winter and summer months\n",
    "    winter_months = [10, 11, 12, 1, 2, 3, 4]  # Oct–Apr\n",
    "    summer_months = [5, 6, 7, 8, 9]           # May–Sep\n",
    "\n",
    "    def classify_season(date):\n",
    "        if date.month in winter_months:\n",
    "            return 'winter'\n",
    "        else:\n",
    "            return 'summer'\n",
    "\n",
    "    def season_year(date):\n",
    "        # Winter belongs to the year of January (e.g., winter 1914-15 -> 1915)\n",
    "        if date.month >= 10:\n",
    "            return date.year + 1  # Oct–Dec -> next year\n",
    "        else:\n",
    "            return date.year\n",
    "\n",
    "    def compute_season_date(row):\n",
    "        season_year, season = row.name  # MultiIndex: (season_year, season)\n",
    "        if season == \"winter\":\n",
    "            return pd.Timestamp(season_year - 1, 10, 1)\n",
    "        else:  # summer\n",
    "            return pd.Timestamp(season_year, 5, 1)\n",
    "\n",
    "    # Create a copy of the city data\n",
    "    city_seasonal = city_data.copy()\n",
    "\n",
    "    # Classify seasons and season years\n",
    "    city_seasonal['season'] = city_seasonal.index.to_series().apply(classify_season)\n",
    "    city_seasonal['season_year'] = city_seasonal.index.to_series().apply(season_year)\n",
    "\n",
    "    # Calculate seasonal precipitation\n",
    "    seasonal_sum = (\n",
    "        city_seasonal[['total precipitation (mm)', 'season', 'season_year']]\n",
    "        .groupby(['season_year', 'season'])\n",
    "        .sum()\n",
    "    )\n",
    "\n",
    "    # Calculate seasonal temperature\n",
    "    city_seasonal['days_in_month'] = city_seasonal.index.days_in_month\n",
    "    city_seasonal['temp_times_days'] = city_seasonal['mean temperature (°C)'] * city_seasonal['days_in_month']\n",
    "    seasonal_temp = (\n",
    "        city_seasonal.groupby(['season_year', 'season'])\n",
    "        .apply(lambda df: df['temp_times_days'].sum() / df['days_in_month'].sum())\n",
    "        .to_frame(name='mean seasonal temperature (°C)')\n",
    "    )\n",
    "\n",
    "    # Combine seasonal data\n",
    "    seasonal_data = pd.concat([seasonal_sum, seasonal_temp], axis=1)\n",
    "    seasonal_data = seasonal_data.round(1)\n",
    "    seasonal_data['date'] = seasonal_data.apply(compute_season_date, axis=1)\n",
    "    seasonal_data = seasonal_data.set_index('date').sort_index().reset_index()\n",
    "\n",
    "    # Separate winter and summer data\n",
    "    weather_winter = seasonal_data.iloc[::2, :].reset_index(drop=True)\n",
    "    weather_summer = seasonal_data.iloc[1::2, :].reset_index(drop=True)\n",
    "\n",
    "    # Rename columns\n",
    "    weather_summer.rename(\n",
    "        columns={\n",
    "            'total precipitation (mm)': 'summer total precipitation (mm)',\n",
    "            'mean seasonal temperature (°C)': 'summer mean temperature (°C)'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    weather_winter.rename(\n",
    "        columns={\n",
    "            'total precipitation (mm)': 'winter total precipitation (mm)',\n",
    "            'mean seasonal temperature (°C)': 'winter mean temperature (°C)'\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    return weather_winter, weather_summer\n",
    "\n",
    "def calculate_weather_deviations_1961_1990(city_data, city_name):\n",
    "    \"\"\"\n",
    "    Calculate monthly temperature and precipitation deviations from 1961-1990 norms.\n",
    "    Returns two DataFrames: temp_dev_1961_1990 and precip_dev_1961_1990.\n",
    "    \"\"\"\n",
    "    # Define norms for each city (temperature and precipitation)\n",
    "    norms = {\n",
    "        'sion': {\n",
    "            'temp': [9.5, 3.4, -0.4, -0.8, -1.6, -5.3, -9.4, -13.7, -17.0, -19.1, -17.9, -14.6],\n",
    "            'precip': [50, 60, 61, 53, 57, 48, 36, 41, 52, 48, 55, 38]\n",
    "        },\n",
    "        'davos': {\n",
    "            'temp': [4.7, -1.0, -4.4, -5.3, -4.7, -2.2, 1.3, 5.9, 9.0, 11.3, 10.8, 8.3],\n",
    "            'precip': [58, 66, 65, 68, 59, 60, 55, 91, 120, 132, 135, 90]\n",
    "        },\n",
    "        'altdorf': {\n",
    "            'temp': [9.8, 4.6, 1.0, 0.5, 1.9, 4.6, 8.2, 12.5, 15.5, 17.6, 16.8, 14.0],\n",
    "            'precip': [73, 81, 75, 71, 68, 71, 86, 99, 130, 132, 133, 86]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Extract temperature and precipitation data\n",
    "    city_temp = city_data[['ths200m0']].copy().reset_index(drop=True)\n",
    "    city_precip = city_data[['rhs150m0']].copy().reset_index(drop=True)\n",
    "\n",
    "    # Pivot temperature data\n",
    "    city_temp['year'] = city_temp.index // 12\n",
    "    city_temp['month'] = city_temp.index % 12\n",
    "    temp_dev_1961_1990 = city_temp.pivot(index='year', columns='month', values='ths200m0')\n",
    "\n",
    "    # Rename columns for temperature deviations\n",
    "    monthly_observations_t = [\n",
    "        'october_td', 'november_td', 'december_td',\n",
    "        'january_td', 'february_td', 'march_td',\n",
    "        'april_td', 'may_td', 'june_td',\n",
    "        'july_td', 'august_td', 'september_td'\n",
    "    ]\n",
    "    temp_dev_1961_1990.columns = monthly_observations_t\n",
    "\n",
    "    # Add hydrological year column\n",
    "    temp_dev_1961_1990['hydrological year'] = [f\"{1914 + i}-{1915 + i}\" for i in range(len(temp_dev_1961_1990))]\n",
    "\n",
    "    # Calculate temperature deviations\n",
    "    for i, month in enumerate(monthly_observations_t):\n",
    "        temp_dev_1961_1990[month] -= norms[city_name]['temp'][i]\n",
    "\n",
    "    # Pivot precipitation data\n",
    "    city_precip['year'] = city_precip.index // 12\n",
    "    city_precip['month'] = city_precip.index % 12\n",
    "    precip_dev_1961_1990 = city_precip.pivot(index='year', columns='month', values='rhs150m0')\n",
    "\n",
    "    # Rename columns for precipitation deviations\n",
    "    monthly_observations_p = [\n",
    "        'october_pd', 'november_pd', 'december_pd',\n",
    "        'january_pd', 'february_pd', 'march_pd',\n",
    "        'april_pd', 'may_pd', 'june_pd',\n",
    "        'july_pd', 'august_pd', 'september_pd'\n",
    "    ]\n",
    "    precip_dev_1961_1990.columns = monthly_observations_p\n",
    "\n",
    "    # Add hydrological year column\n",
    "    precip_dev_1961_1990['hydrological year'] = [f\"{1914 + i}-{1915 + i}\" for i in range(len(precip_dev_1961_1990))]\n",
    "\n",
    "    # Calculate precipitation deviations\n",
    "    for i, month in enumerate(monthly_observations_p):\n",
    "        precip_dev_1961_1990[month] -= norms[city_name]['precip'][i]\n",
    "\n",
    "    # Add seasonal aggregates for precipitation\n",
    "    precip_dev_1961_1990['opt_season_pd'] = precip_dev_1961_1990[\n",
    "        ['october_pd', 'november_pd', 'december_pd', 'january_pd', 'february_pd']\n",
    "    ].sum(axis=1)\n",
    "    precip_dev_1961_1990['opt_season+march_pd'] = precip_dev_1961_1990[\n",
    "        ['october_pd', 'november_pd', 'december_pd', 'january_pd', 'february_pd', 'march_pd']\n",
    "    ].sum(axis=1)\n",
    "    precip_dev_1961_1990['winter_pd'] = precip_dev_1961_1990[\n",
    "        ['october_pd', 'november_pd', 'december_pd', 'january_pd', 'february_pd', 'march_pd', 'april_pd']\n",
    "    ].sum(axis=1)\n",
    "\n",
    "    # Add seasonal aggregates for temperature\n",
    "    temp_dev_1961_1990['opt_season_td'] = (\n",
    "        temp_dev_1961_1990['may_td'] * 31 +\n",
    "        temp_dev_1961_1990['june_td'] * 30 +\n",
    "        temp_dev_1961_1990['july_td'] * 31 +\n",
    "        temp_dev_1961_1990['august_td'] * 31\n",
    "    ) / 123\n",
    "    temp_dev_1961_1990['summer_td'] = (\n",
    "        temp_dev_1961_1990['may_td'] * 31 +\n",
    "        temp_dev_1961_1990['june_td'] * 30 +\n",
    "        temp_dev_1961_1990['july_td'] * 31 +\n",
    "        temp_dev_1961_1990['august_td'] * 31 +\n",
    "        temp_dev_1961_1990['september_td'] * 30\n",
    "    ) / 153\n",
    "\n",
    "    # Round values\n",
    "    temp_dev_1961_1990 = temp_dev_1961_1990.round(1)\n",
    "    precip_dev_1961_1990 = precip_dev_1961_1990.round(1)\n",
    "\n",
    "    return temp_dev_1961_1990, precip_dev_1961_1990\n",
    "\n",
    "\n",
    "def calculate_weather_deviations_1991_2020(city_data, city_name):\n",
    "    \"\"\"\n",
    "    Calculate monthly temperature deviations (from th9120mv) and precipitation deviations from 1991-2020 norms.\n",
    "    Returns two DataFrames: temp_dev_1991_2020 and precip_dev_1991_2020.\n",
    "    \"\"\"\n",
    "    # Define precipitation norms for each city (1991-2020)\n",
    "    precip_norms = {\n",
    "        'sion': [43, 50, 68, 52, 40, 37, 34, 52, 62, 60, 38],\n",
    "        'davos': [77, 71, 68, 70, 52, 57, 54, 89, 133, 150, 96],\n",
    "        'altdorf': [84, 81, 83, 70, 59, 72, 81, 117, 141, 154, 105]\n",
    "    }\n",
    "\n",
    "    # Extract temperature deviation and precipitation data\n",
    "    city_temp_dev = city_data[['th9120mv']].copy().reset_index(drop=True)\n",
    "    city_precip = city_data[['rhs150m0']].copy().reset_index(drop=True)\n",
    "\n",
    "    # Pivot temperature deviation data\n",
    "    city_temp_dev['year'] = city_temp_dev.index // 12\n",
    "    city_temp_dev['month'] = city_temp_dev.index % 12\n",
    "    temp_dev_1991_2020 = city_temp_dev.pivot(index='year', columns='month', values='th9120mv')\n",
    "\n",
    "    # Rename columns for temperature deviations\n",
    "    monthly_observations_t = [\n",
    "        'october_td', 'november_td', 'december_td',\n",
    "        'january_td', 'february_td', 'march_td',\n",
    "        'april_td', 'may_td', 'june_td',\n",
    "        'july_td', 'august_td', 'september_td'\n",
    "    ]\n",
    "    temp_dev_1991_2020.columns = monthly_observations_t\n",
    "\n",
    "    # Add hydrological year column\n",
    "    temp_dev_1991_2020['hydrological year'] = [f\"{1914 + i}-{1915 + i}\" for i in range(len(temp_dev_1991_2020))]\n",
    "    temp_dev_1991_2020 = temp_dev_1991_2020.reset_index(drop=True)\n",
    "\n",
    "    # Pivot precipitation data\n",
    "    city_precip['year'] = city_precip.index // 12\n",
    "    city_precip['month'] = city_precip.index % 12\n",
    "    precip_dev_1991_2020 = city_precip.pivot(index='year', columns='month', values='rhs150m0')\n",
    "\n",
    "    # Rename columns for precipitation deviations\n",
    "    monthly_observations_p = [\n",
    "        'october_pd', 'november_pd', 'december_pd',\n",
    "        'january_pd', 'february_pd', 'march_pd',\n",
    "        'april_pd', 'may_pd', 'june_pd',\n",
    "        'july_pd', 'august_pd', 'september_pd'\n",
    "    ]\n",
    "    precip_dev_1991_2020.columns = monthly_observations_p\n",
    "\n",
    "    # Add hydrological year column\n",
    "    precip_dev_1991_2020['hydrological year'] = [f\"{1914 + i}-{1915 + i}\" for i in range(len(precip_dev_1991_2020))]\n",
    "    precip_dev_1991_2020 = precip_dev_1991_2020.reset_index(drop=True)\n",
    "\n",
    "    # Calculate precipitation deviations\n",
    "    for i, month in enumerate(monthly_observations_p[:-1]):  # Exclude September for now\n",
    "        precip_dev_1991_2020[month] -= precip_norms[city_name][i]\n",
    "\n",
    "    # Add September norm (last element in the list)\n",
    "    precip_dev_1991_2020['september_pd'] -= precip_norms[city_name][-1]\n",
    "\n",
    "    # Add seasonal aggregates for precipitation\n",
    "    precip_dev_1991_2020['opt_season_pd'] = precip_dev_1991_2020[\n",
    "        ['october_pd', 'november_pd', 'december_pd', 'january_pd', 'february_pd']\n",
    "    ].sum(axis=1)\n",
    "    precip_dev_1991_2020['opt_season+march_pd'] = precip_dev_1991_2020[\n",
    "        ['october_pd', 'november_pd', 'december_pd', 'january_pd', 'february_pd', 'march_pd']\n",
    "    ].sum(axis=1)\n",
    "    precip_dev_1991_2020['winter_pd'] = precip_dev_1991_2020[\n",
    "        ['october_pd', 'november_pd', 'december_pd', 'january_pd', 'february_pd', 'march_pd', 'april_pd']\n",
    "    ].sum(axis=1)\n",
    "\n",
    "    # Add seasonal aggregates for temperature\n",
    "    temp_dev_1991_2020['opt_season_td'] = (\n",
    "        temp_dev_1991_2020['may_td'] * 31 +\n",
    "        temp_dev_1991_2020['june_td'] * 30 +\n",
    "        temp_dev_1991_2020['july_td'] * 31 +\n",
    "        temp_dev_1991_2020['august_td'] * 31\n",
    "    ) / 123\n",
    "    temp_dev_1991_2020['summer_td'] = (\n",
    "        temp_dev_1991_2020['may_td'] * 31 +\n",
    "        temp_dev_1991_2020['june_td'] * 30 +\n",
    "        temp_dev_1991_2020['july_td'] * 31 +\n",
    "        temp_dev_1991_2020['august_td'] * 31 +\n",
    "        temp_dev_1991_2020['september_td'] * 30\n",
    "    ) / 153\n",
    "\n",
    "    # Round values\n",
    "    temp_dev_1991_2020 = temp_dev_1991_2020.round(1)\n",
    "    precip_dev_1991_2020 = precip_dev_1991_2020.round(1)\n",
    "\n",
    "    return temp_dev_1991_2020, precip_dev_1991_2020\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d0aa3d6-995a-4c9c-a4c0-b6a9fba2e761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2240/866597061.py:366: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda df: df['temp_times_days'].sum() / df['days_in_month'].sum())\n",
      "/tmp/ipykernel_2240/866597061.py:366: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda df: df['temp_times_days'].sum() / df['days_in_month'].sum())\n",
      "/tmp/ipykernel_2240/866597061.py:366: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda df: df['temp_times_days'].sum() / df['days_in_month'].sum())\n"
     ]
    }
   ],
   "source": [
    "# Path to data folders\n",
    "data_path = \"project-glaciers/data\"\n",
    "raw_data_path = \"project-glaciers/data/raw_data\"\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.makedirs(raw_data_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# Load raw data\n",
    "raw_glaciers_df = pd.read_csv(os.path.join(raw_data_path, \"glaciers_list_raw.csv\"), delimiter='\\t', skiprows=4)\n",
    "raw_length_df = pd.read_csv(os.path.join(raw_data_path, \"length_change_raw.csv\"), delimiter='\\t', skiprows=4)\n",
    "\n",
    "# Process the data\n",
    "glaciers_list_clean = process_glaciers_list(raw_glaciers_df)\n",
    "length_change_clean = process_length_change(raw_length_df)\n",
    "\n",
    "\n",
    "# Load raw data for mass balance\n",
    "raw_mass_balance_hy_df = pd.read_csv(os.path.join(raw_data_path, \"mass_balance_hy_raw.csv\"), delimiter='\\t', skiprows=4)\n",
    "raw_mass_balance_hy_eb_df = pd.read_csv(os.path.join(raw_data_path, \"mass_balance_hy_eb_raw.csv\"), delimiter='\\t', skiprows=4)\n",
    "\n",
    "# Process the data\n",
    "mass_balance_hy_clean = process_mass_balance_hy(raw_mass_balance_hy_df)\n",
    "mass_balance_hy_eb_clean = process_mass_balance_hy_eb(raw_mass_balance_hy_eb_df)\n",
    "\n",
    "# Create CSV files with the cleaned dataframes to work further\n",
    "glaciers_list_clean.to_csv(os.path.join(data_path, \"glaciers_list.csv\"), index=False)\n",
    "length_change_clean.to_csv(os.path.join(data_path, \"length_change.csv\"), index=False)\n",
    "mass_balance_hy_clean.to_csv(os.path.join(data_path, \"mass_balance_hy.csv\"), index=False)\n",
    "mass_balance_hy_eb_clean.to_csv(os.path.join(data_path, \"mass_balance_hy_eb.csv\"), index=False)\n",
    "\n",
    "\n",
    "\n",
    "# Read weather data files\n",
    "sion_weather_raw = pd.read_csv(os.path.join(raw_data_path, \"weather_data_sion_raw.csv\"), delimiter=',')\n",
    "davos_weather_raw = pd.read_csv(os.path.join(raw_data_path, \"weather_data_davos_raw.csv\"), delimiter=',')\n",
    "altdorf_weather_raw = pd.read_csv(os.path.join(raw_data_path, \"weather_data_altdorf_raw.csv\"), delimiter=',')\n",
    "weather_metadata_raw = pd.read_csv(os.path.join(raw_data_path, \"weather_metadata_raw.csv\"), delimiter=',')\n",
    "\n",
    "\n",
    "\n",
    "# Process weather data for each city\n",
    "sion = process_city_weather(sion_weather_raw)\n",
    "davos = process_city_weather(davos_weather_raw)\n",
    "altdorf = process_city_weather(altdorf_weather_raw)\n",
    "\n",
    "# Calculate hydrological year aggregates for each city\n",
    "hy_data_sion = calculate_hydrological_year_aggregates(sion)\n",
    "hy_data_davos = calculate_hydrological_year_aggregates(davos)\n",
    "hy_data_altdorf = calculate_hydrological_year_aggregates(altdorf)\n",
    "\n",
    "\n",
    "# Calculate seasonal aggregates for each city\n",
    "sion_winter, sion_summer = calculate_seasonal_aggregates(sion)\n",
    "davos_winter, davos_summer = calculate_seasonal_aggregates(davos)\n",
    "altdorf_winter, altdorf_summer = calculate_seasonal_aggregates(altdorf)\n",
    "\n",
    "\n",
    "# Load and prepare data for each city\n",
    "sion_before_dev = pd.read_csv('project-glaciers/data/raw_data/weather_data_sion_raw.csv')\n",
    "sion_before_dev['date'] = pd.to_datetime(sion_before_dev['reference_timestamp'], format='%d.%m.%Y %H:%M')\n",
    "sion_before_dev = sion_before_dev.set_index('date')\n",
    "sion_before_dev = sion_before_dev[(sion_before_dev.index >= '1914-10-01') & (sion_before_dev.index < '2025-10-01')]\n",
    "\n",
    "davos_before_dev = pd.read_csv('project-glaciers/data/raw_data/weather_data_davos_raw.csv')\n",
    "davos_before_dev['date'] = pd.to_datetime(davos_before_dev['reference_timestamp'], format='%d.%m.%Y %H:%M')\n",
    "davos_before_dev = davos_before_dev.set_index('date')\n",
    "davos_before_dev = davos_before_dev[(davos_before_dev.index >= '1914-10-01') & (davos_before_dev.index < '2025-10-01')]\n",
    "\n",
    "altdorf_before_dev = pd.read_csv('project-glaciers/data/raw_data/weather_data_altdorf_raw.csv')\n",
    "altdorf_before_dev['date'] = pd.to_datetime(altdorf_before_dev['reference_timestamp'], format='%d.%m.%Y %H:%M')\n",
    "altdorf_before_dev = altdorf_before_dev.set_index('date')\n",
    "altdorf_before_dev = altdorf_before_dev[(altdorf_before_dev.index >= '1914-10-01') & (altdorf_before_dev.index < '2025-10-01')]\n",
    "\n",
    "# Calculate deviations from 1961-1990 norms\n",
    "sion_temp_dev_6190, sion_precip_dev6190 = calculate_weather_deviations_1961_1990(sion_before_dev, 'sion')\n",
    "davos_temp_dev6190, davos_precip_dev6190 = calculate_weather_deviations_1961_1990(davos_before_dev, 'davos')\n",
    "altdorf_temp_dev6190, altdorf_precip_dev6190 = calculate_weather_deviations_1961_1990(altdorf_before_dev, 'altdorf')\n",
    "\n",
    "\n",
    "# Calculate deviations from 1991-2020 norms\n",
    "sion_temp_dev_9120, sion_precip_dev = calculate_weather_deviations_1991_2020(sion_before_dev, 'sion')\n",
    "davos_temp_dev_9120, davos_precip_dev = calculate_weather_deviations_1991_2020(davos_before_dev, 'davos')\n",
    "altdorf_temp_dev_9120, altdorf_precip_dev = calculate_weather_deviations_1991_2020(altdorf_before_dev, 'altdorf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2796be-87fa-48f0-b2c8-e0e9c5945a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
