{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42a828e-9058-43ba-95de-0411876e2784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Regression Analysis ---\n",
    "def load_data(norm_period):\n",
    "    mass_balance_df = pd.read_csv('project-glaciers/data/mass_balance_hy.csv').iloc[::-1].reset_index(drop=True)\n",
    "    if norm_period == \"1961-1990\":\n",
    "        davos_dev_temp = pd.read_csv('project-glaciers/data/weather_dev6190_davos_temp.csv').iloc[::-1].reset_index(drop=True)\n",
    "        davos_dev_prec = pd.read_csv('project-glaciers/data/weather_dev6190_davos_prec.csv').iloc[::-1].reset_index(drop=True)\n",
    "        sion_dev_temp = pd.read_csv('project-glaciers/data/weather_dev6190_sion_temp.csv').iloc[::-1].reset_index(drop=True)\n",
    "        sion_dev_prec = pd.read_csv('project-glaciers/data/weather_dev6190_sion_prec.csv').iloc[::-1].reset_index(drop=True)\n",
    "        altdorf_dev_temp = pd.read_csv('project-glaciers/data/weather_dev6190_altdorf_temp.csv').iloc[::-1].reset_index(drop=True)\n",
    "        altdorf_dev_prec = pd.read_csv('project-glaciers/data/weather_dev6190_altdorf_prec.csv').iloc[::-1].reset_index(drop=True)\n",
    "    else:\n",
    "        davos_dev_temp = pd.read_csv('project-glaciers/data/weather_dev9120_davos_temp.csv').iloc[::-1].reset_index(drop=True)\n",
    "        davos_dev_prec = pd.read_csv('project-glaciers/data/weather_dev9120_davos_prec.csv').iloc[::-1].reset_index(drop=True)\n",
    "        sion_dev_temp = pd.read_csv('project-glaciers/data/weather_dev9120_sion_temp.csv').iloc[::-1].reset_index(drop=True)\n",
    "        sion_dev_prec = pd.read_csv('project-glaciers/data/weather_dev9120_sion_prec.csv').iloc[::-1].reset_index(drop=True)\n",
    "        altdorf_dev_temp = pd.read_csv('project-glaciers/data/weather_dev9120_altdorf_temp.csv').iloc[::-1].reset_index(drop=True)\n",
    "        altdorf_dev_prec = pd.read_csv('project-glaciers/data/weather_dev9120_altdorf_prec.csv').iloc[::-1].reset_index(drop=True)\n",
    "    glacier_mappings = {\n",
    "        'Grosser Aletschgletscher': {'temp': sion_dev_temp, 'prec': sion_dev_prec},\n",
    "        'Allalingletscher': {'temp': sion_dev_temp, 'prec': sion_dev_prec},\n",
    "        'Griesgletscher': {'temp': sion_dev_temp, 'prec': sion_dev_prec},\n",
    "        'Schwarzberggletscher': {'temp': sion_dev_temp, 'prec': sion_dev_prec},\n",
    "        'Hohlaubgletscher': {'temp': sion_dev_temp, 'prec': sion_dev_prec},\n",
    "        'Glacier du Gi√©tro': {'temp': sion_dev_temp, 'prec': sion_dev_prec},\n",
    "        'Silvrettagletscher': {'temp': davos_dev_temp, 'prec': davos_dev_prec},\n",
    "        'Claridenfirn': {'temp': altdorf_dev_temp, 'prec': altdorf_dev_prec}\n",
    "    }\n",
    "    return mass_balance_df, glacier_mappings\n",
    "\n",
    "def run_regression_analysis(mass_balance_df, glacier_mappings, temp_cols, prec_cols, analysis_name, norm_period):\n",
    "    captured_output = StringIO()\n",
    "    sys.stdout = captured_output\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{analysis_name} ANALYSIS USING {norm_period} CLIMATE NORMS\")\n",
    "    print('='*80)\n",
    "    for glacier_name, weather_data in glacier_mappings.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"{analysis_name} for {glacier_name} ({norm_period} norms)\")\n",
    "        print('='*80)\n",
    "        try:\n",
    "            mb_data = mass_balance_df[mass_balance_df['glacier name'] == glacier_name][['annual mass balance (mm w.e.)']].copy()\n",
    "            mb_data = mb_data.reset_index(drop=True)\n",
    "            if len(mb_data) == 0:\n",
    "                print(f\"No mass balance data found for {glacier_name}\")\n",
    "                continue\n",
    "            if glacier_name == 'Claridenfirn':\n",
    "                temp_df = weather_data['temp'][temp_cols].copy()\n",
    "                prec_df = weather_data['prec'][prec_cols].copy()\n",
    "                temp_years = weather_data['temp']['hydrological year']\n",
    "                prec_years = weather_data['prec']['hydrological year']\n",
    "                temp_df = temp_df[~temp_years.isin(['1993-1994', '1994-1995'])].reset_index(drop=True)\n",
    "                prec_df = prec_df[~prec_years.isin(['1993-1994', '1994-1995'])].reset_index(drop=True)\n",
    "            else:\n",
    "                temp_df = weather_data['temp'][temp_cols].reset_index(drop=True)\n",
    "                prec_df = weather_data['prec'][prec_cols].reset_index(drop=True)\n",
    "            max_index = min(len(mb_data) - 1, len(temp_df) - 1, len(prec_df) - 1)\n",
    "            temp_df = temp_df.iloc[0:max_index+1]\n",
    "            prec_df = prec_df.iloc[0:max_index+1]\n",
    "            reg_data = mb_data.iloc[0:max_index+1].copy()\n",
    "            reg_data = pd.concat([reg_data, temp_df, prec_df], axis=1)\n",
    "            X = reg_data[temp_cols + prec_cols]\n",
    "            y = reg_data['annual mass balance (mm w.e.)']\n",
    "            X = sm.add_constant(X)\n",
    "            reg_data_clean = pd.concat([X, y], axis=1).dropna()\n",
    "            if len(reg_data_clean) == 0:\n",
    "                print(f\"No valid data remaining for {glacier_name} after cleaning\")\n",
    "                continue\n",
    "            model = sm.OLS(reg_data_clean['annual mass balance (mm w.e.)'], reg_data_clean.drop('annual mass balance (mm w.e.)', axis=1)).fit()\n",
    "            print(f\"\\nNumber of observations: {len(reg_data_clean)}\")\n",
    "            print(\"\\nRegression Summary:\")\n",
    "            print(model.summary())\n",
    "            print(\"\\nCoefficient Interpretation:\")\n",
    "            for param in model.params.index:\n",
    "                if param == 'const':\n",
    "                    print(f\"Intercept (normal mass balance): {model.params[param]:.2f} (p={model.pvalues[param]:.4f})\")\n",
    "                else:\n",
    "                    print(f\"{param}: {model.params[param]:.2f} (p={model.pvalues[param]:.4f})\")\n",
    "            print(\"\\nVariance Inflation Factors (VIF):\")\n",
    "            vif_data = pd.DataFrame()\n",
    "            vif_data[\"Variable\"] = X.columns\n",
    "            vif_data[\"VIF\"] = [variance_inflation_factor(reg_data_clean.drop('annual mass balance (mm w.e.)', axis=1).values, i) for i in range(len(X.columns))]\n",
    "            print(vif_data)\n",
    "            print(f\"\\nR-squared: {model.rsquared:.4f}\")\n",
    "            print(f\"Adjusted R-squared: {model.rsquared_adj:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {glacier_name}: {str(e)}\")\n",
    "    sys.stdout = sys.__stdout__\n",
    "    return captured_output.getvalue()\n",
    "\n",
    "def run_all_analyses_for_glacier(glacier_name, norm_periods=[\"1961-1990\", \"1991-2020\"]):\n",
    "    outputs = {}\n",
    "    for norm_period in norm_periods:\n",
    "        mass_balance_df, glacier_mappings = load_data(norm_period)\n",
    "        monthly_temp_cols = ['may_td', 'june_td', 'july_td', 'august_td', 'september_td']\n",
    "        monthly_prec_cols = ['october_pd', 'november_pd', 'december_pd', 'january_pd', 'february_pd', 'march_pd', 'april_pd']\n",
    "        outputs[f\"monthly_{norm_period}\"] = run_regression_analysis(\n",
    "            mass_balance_df, {glacier_name: glacier_mappings[glacier_name]},\n",
    "            monthly_temp_cols, monthly_prec_cols, \"MONTHLY DEVIATIONS\", norm_period\n",
    "        )\n",
    "        opt_temp_cols = ['opt_season_td']\n",
    "        opt_prec_cols = ['opt_season_pd']\n",
    "        outputs[f\"optimal_{norm_period}\"] = run_regression_analysis(\n",
    "            mass_balance_df, {glacier_name: glacier_mappings[glacier_name]},\n",
    "            opt_temp_cols, opt_prec_cols, \"OPTIMAL SEASONAL DEVIATIONS\", norm_period\n",
    "        )\n",
    "        season_temp_cols = ['summer_td']\n",
    "        season_prec_cols = ['winter_pd']\n",
    "        outputs[f\"seasonal_{norm_period}\"] = run_regression_analysis(\n",
    "            mass_balance_df, {glacier_name: glacier_mappings[glacier_name]},\n",
    "            season_temp_cols, season_prec_cols, \"SUMMER/WINTER SEASONAL DEVIATIONS\", norm_period\n",
    "        )\n",
    "    return outputs\n",
    "\n",
    "def plot_regression_text(text, title, figsize=(12, 8)):\n",
    "    fig_reg, ax = plt.subplots(figsize=figsize)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title, fontsize=12)\n",
    "    ax.text(0.01, 0.99, text, fontsize=8, family='monospace', va='top')\n",
    "    plt.tight_layout()\n",
    "    return fig_reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0fe3d1-1f6c-415f-919e-879f5ed5123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import statsmodels.api as sm\n",
    "from io import StringIO\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "length_change_df = pd.read_csv('project-glaciers/data/length_change.csv')\n",
    "mass_balance_hy_df = pd.read_csv('project-glaciers/data/mass_balance_hy.csv')\n",
    "mass_balance_hy_eb_df = pd.read_csv('project-glaciers/data/mass_balance_hy_eb.csv')\n",
    "davos_summer =  pd.read_csv('project-glaciers/data/weather_data_davos_summer.csv')\n",
    "davos_winter = pd.read_csv('project-glaciers/data/weather_data_davos_winter.csv')\n",
    "altdorf_summer =  pd.read_csv('project-glaciers/data/weather_data_altdorf_summer.csv')\n",
    "altdorf_winter = pd.read_csv('project-glaciers/data/weather_data_altdorf_winter.csv')\n",
    "sion_summer =  pd.read_csv('project-glaciers/data/weather_data_sion_summer.csv')\n",
    "sion_winter = pd.read_csv('project-glaciers/data/weather_data_sion_winter.csv')\n",
    "davos_dev_temp = pd.read_csv('project-glaciers/data/weather_dev6190_davos_temp.csv').iloc[::-1].reset_index(drop=True)\n",
    "davos_dev_prec = pd.read_csv('project-glaciers/data/weather_dev6190_davos_prec.csv').iloc[::-1].reset_index(drop=True)\n",
    "sion_dev_temp = pd.read_csv('project-glaciers/data/weather_dev6190_sion_temp.csv').iloc[::-1].reset_index(drop=True)\n",
    "sion_dev_prec = pd.read_csv('project-glaciers/data/weather_dev6190_sion_prec.csv').iloc[::-1].reset_index(drop=True)\n",
    "altdorf_dev_temp = pd.read_csv('project-glaciers/data/weather_dev6190_altdorf_temp.csv').iloc[::-1].reset_index(drop=True)\n",
    "altdorf_dev_prec = pd.read_csv('project-glaciers/data/weather_dev6190_altdorf_prec.csv').iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "# Convert the date column to datetime for all weather dataframes\n",
    "for df in [altdorf_summer, altdorf_winter,\n",
    "           davos_summer, davos_winter,\n",
    "           sion_summer, sion_winter]:\n",
    "    # Assuming the date column is named 'date' or similar; adjust if needed\n",
    "    date_col = 'date'  # Replace with the actual column name if different\n",
    "    df[date_col] = pd.to_datetime(df[date_col])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
